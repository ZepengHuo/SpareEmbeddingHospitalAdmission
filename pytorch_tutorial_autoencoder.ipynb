{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.4\n",
    "matplotlib\n",
    "numpy\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.005         # learning rate\n",
    "DOWNLOAD_MNIST = False\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "# Mnist digits dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,                        # download it if you don't have it\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "plt.imshow(train_data.train_data[4].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[2])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 3),   # compress to 3 features which can be visualized in plt\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid(),       # compress to a range (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "\n",
    "autoencoder = AutoEncoder()\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "# initialize figure\n",
    "f, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\n",
    "plt.ion()   # continuously plot\n",
    "\n",
    "\n",
    "# original data (first row) for viewing\n",
    "view_data = train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.\n",
    "for i in range(N_TEST_IMG):\n",
    "    a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, b_label) in enumerate(train_loader):\n",
    "        b_x = x.view(-1, 28*28)   # batch x, shape (batch, 28*28)\n",
    "        b_y = x.view(-1, 28*28)   # batch y, shape (batch, 28*28)\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data)\n",
    "            for i in range(N_TEST_IMG):\n",
    "                a[1][i].clear()\n",
    "                a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n",
    "                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "            plt.draw(); plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# visualize in 3D plot\n",
    "view_data = train_data.train_data[:200].view(-1, 28*28).type(torch.FloatTensor)/255.\n",
    "encoded_data, _ = autoencoder(view_data)\n",
    "fig = plt.figure(2); ax = Axes3D(fig)\n",
    "X, Y, Z = encoded_data.data[:, 0].numpy(), encoded_data.data[:, 1].numpy(), encoded_data.data[:, 2].numpy()\n",
    "values = train_data.train_labels[:200].numpy()\n",
    "for x, y, z, s in zip(X, Y, Z, values):\n",
    "    c = cm.rainbow(int(255*s/9)); ax.text(x, y, z, s, backgroundcolor=c)\n",
    "ax.set_xlim(X.min(), X.max()); ax.set_ylim(Y.min(), Y.max()); ax.set_zlim(Z.min(), Z.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
